{
  "DBDRIVER": {"userlvl":"basic","type":"select","values":["postgresql"],"description":"Primary database handler. Currently only postgresql.","_title":"Main Configuration"},
  "PLAYER_NAME": {"userlvl":"basic","type":"string","description":"Your current character name."},
  "HERIKA_NAME": {"userlvl":"basic","type":"string","description":"NPC Name. MUST MATCH Skyrim in-game NPC name!."},
  "PROMPT_HEAD": {"userlvl":"basic","type":"longstring","description":"System Prompt. Defines the rules of the roleplay."},
  "HERIKA_PERS": {"userlvl":"basic","type":"longstring","description":"Follower Personality. Treat it like a DnD character bio.","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5321"},
  "dynamic_profile_b1": {"userlvl":"wip","type":"util","description":"Use LLM (non json model in this profile) to fill personality data, <strong>based on last events</strong>. Make sure your connector has max_tokens to a value about 400/500","action":"action_dynamic_profile_b1.php","name":"Auto Fill","helpurl":""},
  "dynamic_profile_b2": {"userlvl":"wip","type":"util","description":"Use LLM (non json model in this profile) to fill personality data, <strong>based on last events</strong>. This is a shorter version for NPCs.  Make sure your connector has max_tokens to a value about 200/300","action":"action_dynamic_profile_b1.php?short=yes","name":"Auto Fill","helpurl":""},
  "DYNAMIC_PROFILE":{"userlvl":"wip","type":"boolean","description":"Will trigger above button from time to time, so personality will be updated by AI WIP!!!"},
  "RECHAT_H": {"userlvl":"pro","type":"integer","description":"Rechat lines. Higher values will make followers keep talking between themselves.","_title":"Advanced Configuration"},
  "RECHAT_P": {"userlvl":"pro","type":"integer","description":"Rechat probability. 0 = Always | 100 = Never"},
  "BORED_EVENT": {"userlvl":"pro","type":"integer","description":"Bored Event Probability. Chance of an NPC starting a random conversation. 0 = NEVER | 1 = 50% | 2 = 75% ..."},
  "CONTEXT_HISTORY": {"userlvl":"basic","type":"integer","description":"Amount of context history (dialogue and events) that will be pushed to LLM. Improves short term memory. More context = more tokens used, and slower response time."},
  "HTTP_TIMEOUT": {"userlvl":"pro","type":"integer","description":"Timeout for AI requests. "},
  "CORE_LANG": {"userlvl":"pro","type":"select","description":"Custom Language. The lang folder is in the AI Follower Framework Server. Leave it blank for English."},
  "NEWQUEUE": {"userlvl":"basic","scope":"constant","type":"boolean","description":"Leave as is. Can not be changed!"},
  "MAX_WORDS_LIMIT": {"userlvl":"basic","type":"integer","description":"Enforce a word limit for AI's responses. Leave as 0 to disable."},
  "BOOK_EVENT_FULL": {"userlvl":"wip","type":"boolean","description":"Send book contents instead of book titles. This will consume more tokens, but AI could summarize any book."},
  "BOOK_EVENT_ALWAYS_NARRATOR": {"userlvl":"basic","type":"boolean","description":"The Narrator model/tts will take care of reading books. SET THIS ON default profile to apply to all followers.","scope":"global"},
  "NARRATOR_WELCOME": {"userlvl":"basic","type":"boolean","description":"The Narrator will remind you the  game status when loading a game.","scope":"global"},
  "LANG_LLM_XTTS": {"userlvl":"wip","type":"boolean","description":"Will offer a lang field to LLM, and will try match to XTTSv2 language. "},
  "HERIKA_ANIMATIONS": {"userlvl":"pro","type":"boolean","description":"Will issue animations also to NPC"},
  "EMOTEMOODS": {"userlvl":"pro","type":"longstring","description":"List of moods passed to LLM (comma separated). Some of them will trigger animations if passing animations are enabled"},
  "CONNECTORS": {"type":"selectmultiple","values":["openaijson","koboldcppjson","openrouterjson"],"description":"AI Service to use. Are used to connect with an AI service or program.","_title":"AI/LLM Service (JSON MODE)"},
  "CONNECTORS_DIARY": {"type":"select","values":["openai","koboldcpp","openrouter"],"description":"AI Service to use. Are used to connect with an AI service or program. Will use this connector to generate content for diary/memories","_title":"AI/LLM Service "},
  "CONNECTOR": {
    "_title":"AI/LLM Connectors",
    "openai": {
      "_title":"OpenAI/ChatGPT API",
      "url": {"type":"url","description":"OpenAI API endpoint"},
      "model": {"type":"string","description":"Model to use","helpurl":"https://platform.openai.com/docs/models/"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate"},
      "temperature": {"type":"number","description":"LLM parameter temperature","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "presence_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter presence_penalty","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "frequency_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter frequency_penalty","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "API_KEY":  {"type":"apikey","description":"OpenAI API key","code":"OPENAI_API_KEY","helpurl":"https://platform.openai.com/account/api-keys"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."}
    },
    "openaijson": {
      "_title":"OpenAI/ChatGPT API (JSON mode)",
      "url": {"type":"url","description":"OpenAI API endpoint"},
      "model": {"type":"string","description":"Model to use","helpurl":"https://platform.openai.com/docs/models/"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate"},
      "temperature": {"type":"number","description":"LLM parameter temperature","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "presence_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter presence_penalty","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "frequency_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter frequency_penalty","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "API_KEY":  {"type":"apikey","description":"OpenAI API key","code":"OPENAI_API_KEY","helpurl":"https://platform.openai.com/account/api-keys"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."}
    },
    "koboldcpp": {
      "_title":"KoboldCPP API",
      "url": {"type":"url","description":"KoboldCPP API Endpoint","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5742"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate"},
      "temperature": {"type":"number","description":"LLM parameter temperature"},
      "rep_pen": {"userlvl":"pro","type":"number","description":"LLM parameter rep_pen"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p"},
      "min_p": {"userlvl":"pro","type":"number","description":"LLM parameter min_p"},
      "top_k": {"userlvl":"pro","type":"number","description":"LLM parameter top_k"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "newline_as_stopseq": {"type":"boolean","description":"A newline in the output that will be considered a stop sequence. Recommended to leave it as default."},
      "use_default_badwordsids": {"type":"boolean","description":"Unban End of Sentence (EOS) tokens. If set to false the LLM will stop generating when it detects an EOS token."},
      "eos_token": {"type":"string","description":"EOS token LLM uses. Only works if use_default_badwordsids is enabled."},
      "template": {"type":"select","values":["vicuna-1","vicuna-1.1","alpaca","synthia","extended-alpaca","superHOT","chatml","chatml-c","zephyr","openchat","dreamgen","neuralchat","phi","llama3","gromenauer","gemma2"],"description":"Prompt Format. Specified in the HuggingFace model card"}
    },
    "koboldcppjson": {
      "_title":"KoboldCPP API JSON",
      "url": {"type":"url","description":"KoboldCPP API Endpoint","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5742"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate"},
      "temperature": {"type":"number","description":"LLM parameter temperature"},
      "rep_pen": {"type":"number","description":"LLM parameter rep_pen"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p"},
      "min_p": {"userlvl":"pro","type":"number","description":"LLM parameter min_p"},
      "top_k": {"userlvl":"pro","type":"number","description":"LLM parameter top_k"},
      "PREFILL_JSON": {"type":"boolean","description":"Will prefill JSON, which is usefull for some models, and destroy others (WIP)"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "newline_as_stopseq": {"type":"boolean","description":"A newline in the output that will be considered a stop sequence. Recommended to leave it as default."},
      "use_default_badwordsids": {"type":"boolean","description":"Unban End of Sentence (EOS) tokens. If set to false the LLM will stop generating when it detects an EOS token."},
      "eos_token": {"type":"string","description":"EOS token LLM uses. Only works if use_default_badwordsids is enabled."},
      "template": {"type":"select","values":["vicuna-1","vicuna-1.1","alpaca","synthia","extended-alpaca","superHOT","chatml","chatml-c","zephyr","openchat","dreamgen","neuralchat","phi","llama3","gromenauer","gemma2","alpacajson"],"description":"Prompt Format. Specified in the HuggingFace model card"},
      "grammar": {"type":"boolean","description":"Enforces use of JSON grammar. True to enforce (generation speed loss, but json format guaranteed). if false, the generation speed will be better but will depend on the model to produce valid JSON output." }
    },
    "openrouter": {
      "_title":"OpenRouter API",
      "url": {"type":"url","description":"OpenRouter API endpoint"},
      "model": {"type":"ormodellist","description":"Model to use.","helpurl":"https://openrouter.ai/docs#models"},
      "PROVIDER": {"type":"string","description":"Comma separated string of providers. Depends on model. You can check models/providers in OR marketplace","helpurl":"https://openrouter.ai/docs/provider-routing"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate."},
      "temperature": {"type":"number","description":"LLM parameter temperature","helpurl":"https://openrouter.ai/docs#format"},
      "presence_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter presence_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "frequency_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter frequency_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "repetition_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter repetition_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p","helpurl":"https://openrouter.ai/docs#format"},
      "top_k": {"userlvl":"pro","type":"number","description":"LLM parameter top_k","helpurl":"https://openrouter.ai/docs#format"},
      "min_p": {"userlvl":"pro","type":"number","description":"LLM parameter min_p","helpurl":"https://openrouter.ai/docs#format"},
      "top_a": {"userlvl":"pro","type":"number","description":"LLM parameter top_a","helpurl":"https://openrouter.ai/docs#format"},
      "API_KEY":  {"type":"apikey","description":"OpenRouter key","code":"OPENAI_API_KEY"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "xreferer": {"userlvl":"pro","type":"string","description":"Stub needed header. Keep default."},
      "xtitle": {"userlvl":"pro","type":"string","description":"Stub needed header. Keep default."},
      "get_parms1": {"type":"util","description":"Get parameters from openrouter directly (P10)","action":"action_openrouter_get_parm_p1.php?P=10","name":"Get parms P10","helpurl":"https://openrouter.ai/docs/parameters"},
      "get_parms5": {"type":"util","description":"Get parameters from openrouter directly (P50)","action":"action_openrouter_get_parm_p1.php?P=50","name":"Get parms P50","helpurl":"https://openrouter.ai/docs/parameters"},
      "get_parms9": {"type":"util","description":"Get parameters from openrouter directly (P90)","action":"action_openrouter_get_parm_p1.php?P=90","name":"Get parms P90","helpurl":"https://openrouter.ai/docs/parameters"}
      
    },
    "openrouterjson": {
      "_title":"OpenRouter API (JSON MODE)",
      "url": {"type":"url","description":"OpenRouter API endpoint"},
      "model": {"type":"ormodellist","description":"Model to use.","helpurl":"https://openrouter.ai/docs#models"},
      "PROVIDER": {"type":"string","description":"Comma separated string of providers. Depends on model. You can check models/providers in OR marketplace","helpurl":"https://openrouter.ai/docs/provider-routing"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate."},
      "temperature": {"type":"number","description":"LLM parameter temperature","helpurl":"https://openrouter.ai/docs#format"},
      "presence_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter presence_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "frequency_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter frequency_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "repetition_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter repetition_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p","helpurl":"https://openrouter.ai/docs#format"},
      "top_k": {"userlvl":"pro","type":"number","description":"LLM parameter top_k","helpurl":"https://openrouter.ai/docs#format"},
      "min_p": {"userlvl":"pro","type":"number","description":"LLM parameter min_p","helpurl":"https://openrouter.ai/docs#format"},
      "top_a": {"userlvl":"pro","type":"number","description":"LLM parameter top_a","helpurl":"https://openrouter.ai/docs#format"},
      "ENFORCE_JSON": {"type":"boolean","description":"Will try to force JSON. Some models acept this. Other's dont.","helpurl":"https://openrouter.ai/docs#format"},
      "PREFILL_JSON": {"type":"boolean","description":"Will prefill JSON, which is usefull for some models, and destroy others","helpurl":"https://openrouter.ai/docs#format"},
      "top_a": {"userlvl":"pro","type":"number","description":"LLM parameter top_a","helpurl":"https://openrouter.ai/docs#format"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "get_parms1": {"type":"util","description":"Get parameters from openrouter directly (P10)","action":"action_openrouterjson_get_parm_p1.php?P=10","name":"Get parms P10","helpurl":"https://openrouter.ai/docs/parameters"},
      "get_parms5": {"type":"util","description":"Get parameters from openrouter directly (P50)","action":"action_openrouterjson_get_parm_p1.php?P=50","name":"Get parms P50","helpurl":"https://openrouter.ai/docs/parameters"},
      "get_parms9": {"type":"util","description":"Get parameters from openrouter directly (P90)","action":"action_openrouterjson_get_parm_p1.php?P=90","name":"Get parms P90","helpurl":"https://openrouter.ai/docs/parameters"},
      "API_KEY":  {"type":"apikey","description":"OpenRouter key","code":"OPENAI_API_KEY"},
      "xreferer": {"userlvl":"pro","type":"string","description":"Stub needed header. Keep default."},
      "xtitle": {"userlvl":"pro","type":"string","description":"Stub needed header. Keep default."}
    }
  },
  "TTSFUNCTION": {"type":"select","values":["none","mimic3","azure","11labs","gcp","coqui-ai","xvasynth","openai","convai","xtts","stylettsv2","xtts-fastapi"],"description":"Text-to-Speech service options. Used to generate your follower's voice.","_title":"Text-to-Speech Service"},
  "TTS": {
    "_title":"Text-to-Speech Service",
    "AZURE": {
      "_title":"Azure Text-To-Speech",
      "fixedMood": {"type":"string","description":"Force mood (voice style)","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#use-speaking-styles-and-roles"},
      "region": {"type":"string","description":"Region location of your API key"},
      "voice": {"type":"string","description":"Voice","helpurl":"https://speech.microsoft.com/portal/voicegallery"},
      "volume": {"type":"integer","description":"Volume","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"},
      "rate": {"userlvl":"pro","type":"number","description":"Talk speed","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"},
      "countour": {"userlvl":"pro","type":"string","description":"Voice contour","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"},
      "validMoods": {"userlvl":"pro","type":"selectmultiple","values":["angry","chat","cheerful","customerservice","empathetic","excited","friendly","hopeful","narration-professional","newscast-casual","newscast-formal","sad","shouting","terrified","unfriendly","whispering","default","dazed"],"description":"Allowed voice styles"},
      "API_KEY": {"type":"apikey","description":"Azure TTS API KEY","code":"AZURE_API_KEY"}
    },
    "MIMIC3": {
      "_title":"MIMIC3 Text-To-Speech (Automatically installed with DwemerDistro)",
      "URL": {"type":"url","description":"MIMIC3 Service URL. If using DwemerDistro, copy and paste [MIMIC3 Configuration] URL from the console window."},
      "voice": {"type":"string","description":"Voice code"},
      "rate": {"type":"number","description":"Talk speed"},
      "volume": {"type":"integer","description":"Volume"}
    },
    "ELEVEN_LABS": {
      "_title":"ElevenLabs Text-To-Speech",
      "voice_id": {"type":"string","description":"Voice code","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5578"},
      "optimize_streaming_latency": {"type":"string","description":"Optimize Streaming Latency","helpurl":"https://docs.elevenlabs.io/api-reference/text-to-speech"},
      "model_id": {"type":"string","description":"Model ID","helpurl":"https://beta.elevenlabs.io/speech-synthesis"},
      "stability":{"userlvl":"pro","type":"number","description":"Stability"},
      "similarity_boost": {"userlvl":"pro","type":"number","description":"Similarity_Boost"},
      "style": {"type":"number","description":"Style"},
      "API_KEY": {"type":"apikey","description":"Eleven Labs API key.","code":"11LABS_API_KEY"}
    },
    "GCP": {
      "_title":"Google Cloud Platform Text-To-Speech",
      "GCP_SA_FILEPATH": {"type":"string","description":"Google Cloud Platform auth file. Should be placed in the data folder.","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5581"},
      "voice_name":{"type":"string","description":"Voice","helpurl":"https://cloud.google.com/text-to-speech/docs/voices"},
      "voice_languageCode":{"type":"string","description":"Language code","helpurl":"https://developers.google.com/admin-sdk/directory/v1/languages"},
      "ssml_rate":{"type":"number","description":"Rate"},
      "ssml_pitch":{"type":"string","description":"Pitch"}
    },
    "openai": {
      "_title":"OpenAI TTS",
      "endpoint":{"type":"url","description":"Endpoint URL","helpurl":"https://platform.openai.com/docs/guides/text-to-speech"},
      "API_KEY":{"type":"apikey","description":"API KEY"},
      "voice":{"type":"select","values":["alloy", "echo", "fable", "onyx", "nova", "shimmer"],"description":"Voice ID","helpurl":"https://platform.openai.com/docs/guides/text-to-speech"},
      "model_id":{"type":"select","values":["tts-1", "tts-1-hd"],"description":"Model","helpurl":"https://platform.openai.com/docs/guides/text-to-speech"}
    },
    "CONVAI": {
      "_title":"CONVAI TTS",
      "endpoint":{"type":"url","description":"End point URL","helpurl":"https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"},
      "API_KEY":{"type":"apikey","description":"API KEY"},
      "language":{"type":"select","values":["ar", "cmn-CN", "de-DE", "en-US", "es-ES", "es-MX", "es-US", "fr-FR", "hi-IN", "it-IT", "js-JP", "kk-KZ", "ko-KR", "nl-BE", "nl-NL", "pl-PL", "pt-BR", "pt-PT", "ru-RU", "sv-SE", "tr-TR", "vi-VN", "yue-HK", "zh-HK"],"description":"Language","helpurl":"https://platform.openai.com/docs/guides/text-to-speech"},
      "voiceid":{"type":"string","description":"Voice id (check compatability with language)","helpurl":"https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"},
      "description":"VoiceId","helpurl":"https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"
      },
    "XTTSFASTAPI": {
      "_title":"XTTSv2 via fast-api",
      "endpoint":{"type":"url","description":"End point URL","helpurl":""},
      "language":{"type":"select","values":[  "ar","pt","zh-cn", "cs","nl","en","fr", "de", "it", "pl", "ru", "es", "tr","ja", "ko","hu","hi"],"description":"Language"},
      "voiceid":{"type":"string","description":"WAV refernce (must be into server's voice folder)","helpurl":""}
    }
  },
  "STTFUNCTION": {
    "type":"select","values":["whisper","localwhisper","azure"],"description":"Speech-to-Text service options. Translates your voice to text.", 
    "_title":"Speech-to-Text Service"
    },
  "STT": {
  "_title":"Speech-to-Text Service",
    "WHISPER": {
      "_title":"OpenAI's Whisper Speech-to-Text",
      "LANG": {"type":"string","description":"Language to detect for STT."},
      "TRANSLATE": {"type":"boolean","description":"Will try to translate to english."},
      "API_KEY": {"type":"apikey","description":"OpenAI API key. Same used for OpenAI/ChatGPT AI service.","code":"OPENAI_API_KEY"}
    },
    "AZURE": {
      "_title":"Azure Speech-to-Text",
      "LANG": {"type":"string","description":"Language to detect for STT."},
      "profanity": {"type":"select","values":["masked","removed","raw"],"description":"Specifies how to handle profanity in recognition results. Accepted values are:MASKED, which replaces profanity with asterisks. REMOVED, which removes all profanity from the result. RAW, which includes profanity in the result.","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-speech-to-text-short"},
      "API_KEY": {"type":"apikey","description":"Azure API key. Same used for Azure TTS Service.","code":"AZURE_API_KEY"}
    },
    "LOCALWHISPER": {
      "_title":"Local Whisper Speech-to-Text (Installed with DwemerDistro)",
      "URL": {"type":"url","description":"Local whisper endpoint. Leave as Default!","helpurl":"https://www.nexusmods.com/skyrimspecialedition/mods/89931?tab=files"},
      "FORMFIELD": {"type":"select","values":["audio_file","file"],"description":"Form field name for audio file. Sometimes needed to change to file to use another shiper implementations"}

    }
  },
  "ITTFUNCTION": {
    "type":"select","values":["llamacpp","azure","openai"],"description":"Image recognition aka Soulgaze spell. Use OpenAI for OpenRouter!", 
    "_title":"Image Recognition Service"
  },
  "ITT": {
    "_title":"Image Recognition Service",
    "AZURE": {
      "_title":"Azure Image-to-Text (DOES NOT WORK!)",
      "ENDPOINT": {"type":"url","endpoint":"Endpoint URL","scope":"global"},
      "API_KEY": {"type":"apikey","description":"Azure Computer Vision API KEY","code":"AZURE_API_KEY","scope":"global"}
    },
    "LLAMACPP": {
      "_title":"LLama.cpp Server",
      "URL": {"type":"url","description":"URL of the llama.cpp server","helpurl":"https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md","scope":"global"},
      "AI_VISION_PROMPT": {"type":"longstring","description":"Prompt to send to the Vision AI","scope":"global"},
      "AI_PROMPT": {"type":"longstring","description":"Prompt to return to AI Character"}
    },
    "openai": {
      "_title":"OpenAI GPT-4V",
      "url": {"type":"url","description":"OpenAI API endpoint","scope":"global"},
      "model": {"type":"string","description":"Model to use","helpurl":"https://platform.openai.com/docs/models/","scope":"global"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate","scope":"global"},
      "detail": {"type":"select","values":["low","high"],"description":"Low or high fidelity image understanding","helpurl":"https://platform.openai.com/docs/guides/vision?lang=curl","scope":"global"},
      "API_KEY":  {"type":"apikey","description":"OpenAI API key","code":"OPENAI_API_KEY","helpurl":"https://platform.openai.com/account/api-keys","scope":"global"},
      "AI_VISION_PROMPT": {"type":"longstring","description":"Prompt to send to the Vision AI","scope":"global"},
      "AI_PROMPT": {"type":"longstring","description":"Prompt to return to AI Character"}
    }
  },
  "FEATURES": {
    "_title":"Other Features",
    "MEMORY_EMBEDDING": {
      "_title":"Long Term Memory",
      "ENABLED": {"type":"boolean","description":"Enable long term memory.  It uses TXTAI to automatically store memories. It will then provide the most relevant memory with every AI response to be used as context."},
      "TXTAI_URL": {"type":"url","description":"TXTAI REST-API Endpoint. Copy and paste the [TXTAI REST-API] URL from the console window."},
      "MEMORY_TIME_DELAY": {"type":"integer","description":"Time in minutes to wait before using a memory in a prompt. Used to avoid pushing recent dialogues as memories. As that is covered by context history."},
      "MEMORY_CONTEXT_SIZE": {"type":"integer","description":"How many of the most relevant memory records will be injected in prompt."},
      "AUTO_CREATE_SUMMARYS": {"type":"boolean","description":"Will summarize individual memory logs into larger ones. Is more accurate for memory recollection but will use up more tokens. If using koboldcpp, use the multiuser mode to avoid locking."},
      "AUTO_CREATE_SUMMARY_INTERVAL": {"type":"integer","description":"Time frame used to pack summary data. 10 = 13 in-game hours, 5 = 7,5 in-game hours etc"},
      "MEMORY_BIAS_A": {"type":"number","description":"From 0 (never) to 100 (always). Minimal distance to offer memory."},
      "MEMORY_BIAS_B": {"type":"number","description":"From 0 (never) to 100 (always). Minimal distance to offer and endorse memory."}
      
    },
    "MISC": {
      "_title":"Misc features/options",
      "ADD_TIME_MARKS":{"type":"boolean","description":"Add timestamps to the context logs. Helps with memory recollection."},
      "QUEST_COMMENT":{"type":"boolean","description":"If enabled, it will trigger a chat event when new quest is acquired."}
    }
  }
  
}
